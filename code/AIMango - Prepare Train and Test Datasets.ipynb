{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import sklearn.model_selection\n",
    "\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_CSV_PATH = '../C1-P1_Train Dev_fixed/train.csv'\n",
    "TRAIN_CSV_PATH = '../C1-P1_Train Dev_fixed/train_split.csv'\n",
    "VALID_CSV_PATH = '../C1-P1_Train Dev_fixed/dev.csv'\n",
    "\n",
    "ORIGINAL_TRAIN_TEST_DATA_PATH = '../C1-P1_Train Dev_fixed/C1-P1_Train/' \n",
    "# ORIGINAL_TRAIN_DATA_PATH = '../C1-P1_Train Dev_fixed/C1-P1_Train/' \n",
    "ORIGINAL_VALID_DATA_PATH = '../C1-P1_Train Dev_fixed/C1-P1_Dev/' \n",
    "\n",
    "\n",
    "TRAIN_DATA_PATH = '../data/train'\n",
    "VALID_DATA_PATH = '../data/valid'\n",
    "TEST_DATA_PATH = '../data/test'\n",
    "\n",
    "NUM_TEST_DATASET = 100\n",
    "\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data from train dataset. get last 100 records as test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = []\n",
    "new_test_data = []\n",
    "all_data = []\n",
    "\n",
    "TEST_CSV_PATH = '../C1-P1_Train Dev_fixed/test_split.csv'\n",
    "\n",
    "with open(TRAIN_TEST_CSV_PATH) as csv_file:\n",
    "\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "            continue  #header\n",
    "        all_data.append(row)\n",
    "        \n",
    "        line_count += 1\n",
    "        \n",
    "indices = list(range(len(all_data)))\n",
    "\n",
    "random.shuffle(indices)\n",
    "training_dataset, test_dataset = sklearn.model_selection.train_test_split(indices, train_size=len(all_data)-NUM_TEST_DATASET, test_size=NUM_TEST_DATASET)\n",
    "\n",
    "for idx in training_dataset:\n",
    "    new_train_data.append(all_data[idx])\n",
    "for idx in test_dataset:\n",
    "    new_test_data.append(all_data[idx])  \n",
    "\n",
    "with open(TRAIN_CSV_PATH, 'w') as f:\n",
    "\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    writer.writerow(['image_id','label'])\n",
    "    for row in new_train_data:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "with open(TEST_CSV_PATH, 'w') as f:\n",
    "\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    writer.writerow(['image_id','label'])\n",
    "    for row in new_test_data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse csv file and make the folder structure for pytorch test dataset\n",
    "def prepare_file_structure_for_pytoch(csv_path, src_data_path, dst_data_path):\n",
    "    with open(csv_path) as csv_file:\n",
    "\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "                continue  #header\n",
    "\n",
    "            src_path = os.path.join(src_data_path, row[0])\n",
    "            dest_path = os.path.join(dst_data_path, row[1], row[0])\n",
    "            dest_folder_path = os.path.join(dst_data_path, row[1])\n",
    "            if not os.path.exists(dest_folder_path):\n",
    "                os.makedirs(dest_folder_path)\n",
    "            if not os.path.isfile(dest_path):\n",
    "                copyfile(src_path, dest_path)\n",
    "        \n",
    "            line_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/train\n",
    "!rm -rf ../data/test\n",
    "!rm -rf ../data/valid\n",
    "# make file structure for training dataset\n",
    "prepare_file_structure_for_pytoch(TRAIN_CSV_PATH, ORIGINAL_TRAIN_TEST_DATA_PATH, TRAIN_DATA_PATH)\n",
    "    \n",
    "# make file structure for validation dataset\n",
    "prepare_file_structure_for_pytoch(VALID_CSV_PATH, ORIGINAL_VALID_DATA_PATH, VALID_DATA_PATH)\n",
    "\n",
    "# make file structure for test dataset\n",
    "prepare_file_structure_for_pytoch(TEST_CSV_PATH, ORIGINAL_TRAIN_TEST_DATA_PATH, TEST_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
